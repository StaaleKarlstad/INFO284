{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216906d0d7843cd3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fishery dataset: Predicting weight with machine learning\n",
    "\n",
    "In this project, we aim to create machine learning models to predict the live weight of caught of fish from a fishing operation. We will try to uncover important and predictive features of the fishing operations which will be used as parameters in our models. \n",
    "\n",
    "Our goal is to use create three supervised learning models which all predict the same outcome.\n",
    "\n",
    "Our methodology is divided into three parts: \n",
    "\n",
    "**[Part A - Preprocessing](#pre_processing)**\n",
    "\n",
    "This part starts by initializing python and all the libraries we use to process the data. Further we perform exploratory data analysis (EDA) to understand the features, remove anomalies in the dataset and perform normalizations.\n",
    "\n",
    "**Part b - Supervised learning**\n",
    "\n",
    "**Part c - Unsupervised learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecba8fe03b7350c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a id=\"pre_processing\"></a>\n",
    "## Part A - Preprocessing\n",
    "\n",
    "In this part we will analyse and prepare the data for our machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1d3c8ba54dcab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 0 - Importing libraries and reading the data\n",
    "\n",
    "To start the project, we need to import the most common libraries we will use to explore the data. This includes pandas, numpy, matplotlib, seaborn, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:14.384167100Z",
     "start_time": "2024-04-03T13:49:14.079249300Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c876d7ec",
   "metadata": {},
   "source": [
    "### Step 1 - Reading the data\n",
    "\n",
    "The data from the fishery reports are in the form of a CSV file. We read this file into a Pandas dataframe allowing for easy analysis and manipulation.\n",
    "\n",
    "To ensure that the data was sucessfully loaded into the DataFrame, it can be useful to inspect the initial content. To do so we can use the `df.head(n)` function to display the first n rows and the column headers of the dataframe. \n",
    "\n",
    "*NOTE:* The filepath assumes that the csv file is located in a \"Resources\" directory in the project root directory. Please ensure that this directory and file is included prior to running the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18985faf1425b142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T13:49:17.242391200Z",
     "start_time": "2024-04-03T13:49:16.220518900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Melding ID</th>\n",
       "      <th>Meldingstidspunkt</th>\n",
       "      <th>Meldingsdato</th>\n",
       "      <th>Meldingsklokkeslett</th>\n",
       "      <th>Starttidspunkt</th>\n",
       "      <th>Startdato</th>\n",
       "      <th>Startklokkeslett</th>\n",
       "      <th>Startposisjon bredde</th>\n",
       "      <th>Startposisjon lengde</th>\n",
       "      <th>Hovedområde start (kode)</th>\n",
       "      <th>...</th>\n",
       "      <th>Art - FDIR</th>\n",
       "      <th>Art - gruppe (kode)</th>\n",
       "      <th>Art - gruppe</th>\n",
       "      <th>Rundvekt</th>\n",
       "      <th>Lengdegruppe (kode)</th>\n",
       "      <th>Lengdegruppe</th>\n",
       "      <th>Bruttotonnasje 1969</th>\n",
       "      <th>Bruttotonnasje annen</th>\n",
       "      <th>Bredde</th>\n",
       "      <th>Fartøylengde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1497177</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>00:00</td>\n",
       "      <td>31.12.2017</td>\n",
       "      <td>31.12.2017</td>\n",
       "      <td>00:00</td>\n",
       "      <td>-60,35</td>\n",
       "      <td>-46,133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Antarktisk krill</td>\n",
       "      <td>506.0</td>\n",
       "      <td>Antarktisk krill</td>\n",
       "      <td>706714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28 m og over</td>\n",
       "      <td>9432.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,87</td>\n",
       "      <td>133,88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1497178</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30.12.2017 23:21</td>\n",
       "      <td>30.12.2017</td>\n",
       "      <td>23:21</td>\n",
       "      <td>74,885</td>\n",
       "      <td>16,048</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Hyse</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Hyse</td>\n",
       "      <td>9594.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28 m og over</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12,6</td>\n",
       "      <td>56,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1497178</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30.12.2017 23:21</td>\n",
       "      <td>30.12.2017</td>\n",
       "      <td>23:21</td>\n",
       "      <td>74,885</td>\n",
       "      <td>16,048</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Torsk</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Torsk</td>\n",
       "      <td>8510.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28 m og over</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12,6</td>\n",
       "      <td>56,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1497178</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30.12.2017 23:21</td>\n",
       "      <td>30.12.2017</td>\n",
       "      <td>23:21</td>\n",
       "      <td>74,885</td>\n",
       "      <td>16,048</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Blåkveite</td>\n",
       "      <td>301.0</td>\n",
       "      <td>Blåkveite</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28 m og over</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12,6</td>\n",
       "      <td>56,8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1497178</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>01.01.2018</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30.12.2017 23:21</td>\n",
       "      <td>30.12.2017</td>\n",
       "      <td>23:21</td>\n",
       "      <td>74,885</td>\n",
       "      <td>16,048</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Sei</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Sei</td>\n",
       "      <td>134.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28 m og over</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12,6</td>\n",
       "      <td>56,8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Melding ID Meldingstidspunkt Meldingsdato Meldingsklokkeslett  \\\n",
       "0     1497177        01.01.2018   01.01.2018               00:00   \n",
       "1     1497178        01.01.2018   01.01.2018               00:00   \n",
       "2     1497178        01.01.2018   01.01.2018               00:00   \n",
       "3     1497178        01.01.2018   01.01.2018               00:00   \n",
       "4     1497178        01.01.2018   01.01.2018               00:00   \n",
       "\n",
       "     Starttidspunkt   Startdato Startklokkeslett Startposisjon bredde  \\\n",
       "0        31.12.2017  31.12.2017            00:00               -60,35   \n",
       "1  30.12.2017 23:21  30.12.2017            23:21               74,885   \n",
       "2  30.12.2017 23:21  30.12.2017            23:21               74,885   \n",
       "3  30.12.2017 23:21  30.12.2017            23:21               74,885   \n",
       "4  30.12.2017 23:21  30.12.2017            23:21               74,885   \n",
       "\n",
       "  Startposisjon lengde  Hovedområde start (kode)  ...        Art - FDIR  \\\n",
       "0              -46,133                       NaN  ...  Antarktisk krill   \n",
       "1               16,048                      20.0  ...              Hyse   \n",
       "2               16,048                      20.0  ...             Torsk   \n",
       "3               16,048                      20.0  ...         Blåkveite   \n",
       "4               16,048                      20.0  ...               Sei   \n",
       "\n",
       "   Art - gruppe (kode)      Art - gruppe  Rundvekt Lengdegruppe (kode)  \\\n",
       "0                506.0  Antarktisk krill  706714.0                 5.0   \n",
       "1                202.0              Hyse    9594.0                 5.0   \n",
       "2                201.0             Torsk    8510.0                 5.0   \n",
       "3                301.0         Blåkveite     196.0                 5.0   \n",
       "4                203.0               Sei     134.0                 5.0   \n",
       "\n",
       "   Lengdegruppe  Bruttotonnasje 1969  Bruttotonnasje annen Bredde Fartøylengde  \n",
       "0  28 m og over               9432.0                   NaN  19,87       133,88  \n",
       "1  28 m og over               1476.0                   NaN   12,6         56,8  \n",
       "2  28 m og over               1476.0                   NaN   12,6         56,8  \n",
       "3  28 m og over               1476.0                   NaN   12,6         56,8  \n",
       "4  28 m og over               1476.0                   NaN   12,6         56,8  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Resources/elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv', delimiter=';')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaedbc884925f12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2 - Understanding the data\n",
    "\n",
    "Now that we've loaded and validated the data, we can start our analysis. The initial is to familiarize ourselves with the data to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "591b8c73564b3c12",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T14:15:40.755789800Z",
     "start_time": "2024-04-03T14:15:40.750498600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame contents\n",
      "Rows: 305434, Columns: 45\n"
     ]
    }
   ],
   "source": [
    "shape = df.shape\n",
    "print(\"DataFrame contents\")\n",
    "print(f\"Rows: {shape[0]}, Columns: {shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77acd2d361c4a3ce",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T14:45:25.218668500Z",
     "start_time": "2024-04-03T14:45:25.210994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame column names and their datatypes\n"
     ]
    },
    {
     "data": {
      "text/plain": "Melding ID                    int64\nMeldingstidspunkt            object\nMeldingsdato                 object\nMeldingsklokkeslett          object\nStarttidspunkt               object\nStartdato                    object\nStartklokkeslett             object\nStartposisjon bredde         object\nStartposisjon lengde         object\nHovedområde start (kode)    float64\nHovedområde start            object\nLokasjon start (kode)       float64\nHavdybde start                int64\nStopptidspunkt               object\nStoppdato                    object\nStoppklokkeslett             object\nVarighet                      int64\nFangstår                      int64\nStopposisjon bredde          object\nStopposisjon lengde          object\nHovedområde stopp (kode)    float64\nHovedområde stopp            object\nLokasjon stopp (kode)       float64\nHavdybde stopp                int64\nTrekkavstand                float64\nRedskap FAO (kode)           object\nRedskap FAO                  object\nRedskap FDIR (kode)         float64\nRedskap FDIR                 object\nHovedart FAO (kode)          object\nHovedart FAO                 object\nHovedart - FDIR (kode)      float64\nArt FAO (kode)               object\nArt FAO                      object\nArt - FDIR (kode)           float64\nArt - FDIR                   object\nArt - gruppe (kode)         float64\nArt - gruppe                 object\nRundvekt                    float64\nLengdegruppe (kode)         float64\nLengdegruppe                 object\nBruttotonnasje 1969         float64\nBruttotonnasje annen        float64\nBredde                       object\nFartøylengde                 object\ndtype: object"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DataFrame column names and their datatypes\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cf0273a1a1adbe",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T14:36:05.854299600Z",
     "start_time": "2024-04-03T14:36:05.671252100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Melding ID  Hovedområde start (kode)  Lokasjon start (kode)  \\\ncount  3.054340e+05             303433.000000          303433.000000   \nmean   1.658783e+06                 14.463737              19.074712   \nstd    9.130738e+04                 13.001244              18.469340   \nmin    1.497177e+06                  0.000000               0.000000   \n25%    1.567228e+06                  5.000000               7.000000   \n50%    1.674230e+06                  8.000000              12.000000   \n75%    1.735590e+06                 20.000000              24.000000   \nmax    1.800291e+06                 81.000000              87.000000   \n\n       Havdybde start       Varighet       Fangstår  Hovedområde stopp (kode)  \\\ncount   305434.000000  305434.000000  305434.000000             303472.000000   \nmean      -228.025292     537.095526    2017.999941                 14.430415   \nstd        226.062493    2201.624688       0.007677                 12.973150   \nmin      -5388.000000       0.000000    2017.000000                  0.000000   \n25%       -273.000000     123.000000    2018.000000                  5.000000   \n50%       -196.000000     296.000000    2018.000000                  8.000000   \n75%       -128.000000     494.000000    2018.000000                 20.000000   \nmax       1220.000000  125534.000000    2018.000000                 81.000000   \n\n       Lokasjon stopp (kode)  Havdybde stopp  Trekkavstand  \\\ncount          303472.000000   305434.000000  3.054100e+05   \nmean               18.883353     -229.084850  1.566397e+04   \nstd                18.361244      224.277365  9.033085e+04   \nmin                 0.000000    -5388.000000  0.000000e+00   \n25%                 7.000000     -274.000000  2.533000e+03   \n50%                12.000000     -198.000000  7.598000e+03   \n75%                24.000000     -127.000000  2.259900e+04   \nmax                87.000000     1616.000000  1.588863e+07   \n\n       Redskap FDIR (kode)  Hovedart - FDIR (kode)  Art - FDIR (kode)  \\\ncount        305246.000000           300456.000000      300452.000000   \nmean             46.489746             1326.729934        1414.625914   \nstd              13.534202              614.506560         633.188386   \nmin              11.000000              412.000000         211.000000   \n25%              32.000000             1022.000000        1022.000000   \n50%              51.000000             1032.000000        1032.000000   \n75%              55.000000             1038.000000        2202.000000   \nmax              80.000000             6619.000000        6619.000000   \n\n       Art - gruppe (kode)      Rundvekt  Lengdegruppe (kode)  \\\ncount        300452.000000  3.004560e+05        304750.000000   \nmean            259.746585  7.438208e+03             4.575032   \nstd             320.124913  4.281086e+04             0.692769   \nmin             101.000000  0.000000e+00             3.000000   \n25%             201.000000  6.400000e+01             4.000000   \n50%             203.000000  3.000000e+02             5.000000   \n75%             302.000000  2.236000e+03             5.000000   \nmax            9903.000000  1.100000e+06             5.000000   \n\n       Bruttotonnasje 1969  Bruttotonnasje annen  \ncount        234005.000000          74774.000000  \nmean           1408.386975            186.172573  \nstd            1148.384145            165.761157  \nmin             104.000000             21.000000  \n25%             496.000000             87.000000  \n50%            1184.000000            149.000000  \n75%            2053.000000            236.000000  \nmax            9432.000000           1147.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Melding ID</th>\n      <th>Hovedområde start (kode)</th>\n      <th>Lokasjon start (kode)</th>\n      <th>Havdybde start</th>\n      <th>Varighet</th>\n      <th>Fangstår</th>\n      <th>Hovedområde stopp (kode)</th>\n      <th>Lokasjon stopp (kode)</th>\n      <th>Havdybde stopp</th>\n      <th>Trekkavstand</th>\n      <th>Redskap FDIR (kode)</th>\n      <th>Hovedart - FDIR (kode)</th>\n      <th>Art - FDIR (kode)</th>\n      <th>Art - gruppe (kode)</th>\n      <th>Rundvekt</th>\n      <th>Lengdegruppe (kode)</th>\n      <th>Bruttotonnasje 1969</th>\n      <th>Bruttotonnasje annen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3.054340e+05</td>\n      <td>303433.000000</td>\n      <td>303433.000000</td>\n      <td>305434.000000</td>\n      <td>305434.000000</td>\n      <td>305434.000000</td>\n      <td>303472.000000</td>\n      <td>303472.000000</td>\n      <td>305434.000000</td>\n      <td>3.054100e+05</td>\n      <td>305246.000000</td>\n      <td>300456.000000</td>\n      <td>300452.000000</td>\n      <td>300452.000000</td>\n      <td>3.004560e+05</td>\n      <td>304750.000000</td>\n      <td>234005.000000</td>\n      <td>74774.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.658783e+06</td>\n      <td>14.463737</td>\n      <td>19.074712</td>\n      <td>-228.025292</td>\n      <td>537.095526</td>\n      <td>2017.999941</td>\n      <td>14.430415</td>\n      <td>18.883353</td>\n      <td>-229.084850</td>\n      <td>1.566397e+04</td>\n      <td>46.489746</td>\n      <td>1326.729934</td>\n      <td>1414.625914</td>\n      <td>259.746585</td>\n      <td>7.438208e+03</td>\n      <td>4.575032</td>\n      <td>1408.386975</td>\n      <td>186.172573</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.130738e+04</td>\n      <td>13.001244</td>\n      <td>18.469340</td>\n      <td>226.062493</td>\n      <td>2201.624688</td>\n      <td>0.007677</td>\n      <td>12.973150</td>\n      <td>18.361244</td>\n      <td>224.277365</td>\n      <td>9.033085e+04</td>\n      <td>13.534202</td>\n      <td>614.506560</td>\n      <td>633.188386</td>\n      <td>320.124913</td>\n      <td>4.281086e+04</td>\n      <td>0.692769</td>\n      <td>1148.384145</td>\n      <td>165.761157</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.497177e+06</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-5388.000000</td>\n      <td>0.000000</td>\n      <td>2017.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-5388.000000</td>\n      <td>0.000000e+00</td>\n      <td>11.000000</td>\n      <td>412.000000</td>\n      <td>211.000000</td>\n      <td>101.000000</td>\n      <td>0.000000e+00</td>\n      <td>3.000000</td>\n      <td>104.000000</td>\n      <td>21.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.567228e+06</td>\n      <td>5.000000</td>\n      <td>7.000000</td>\n      <td>-273.000000</td>\n      <td>123.000000</td>\n      <td>2018.000000</td>\n      <td>5.000000</td>\n      <td>7.000000</td>\n      <td>-274.000000</td>\n      <td>2.533000e+03</td>\n      <td>32.000000</td>\n      <td>1022.000000</td>\n      <td>1022.000000</td>\n      <td>201.000000</td>\n      <td>6.400000e+01</td>\n      <td>4.000000</td>\n      <td>496.000000</td>\n      <td>87.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.674230e+06</td>\n      <td>8.000000</td>\n      <td>12.000000</td>\n      <td>-196.000000</td>\n      <td>296.000000</td>\n      <td>2018.000000</td>\n      <td>8.000000</td>\n      <td>12.000000</td>\n      <td>-198.000000</td>\n      <td>7.598000e+03</td>\n      <td>51.000000</td>\n      <td>1032.000000</td>\n      <td>1032.000000</td>\n      <td>203.000000</td>\n      <td>3.000000e+02</td>\n      <td>5.000000</td>\n      <td>1184.000000</td>\n      <td>149.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.735590e+06</td>\n      <td>20.000000</td>\n      <td>24.000000</td>\n      <td>-128.000000</td>\n      <td>494.000000</td>\n      <td>2018.000000</td>\n      <td>20.000000</td>\n      <td>24.000000</td>\n      <td>-127.000000</td>\n      <td>2.259900e+04</td>\n      <td>55.000000</td>\n      <td>1038.000000</td>\n      <td>2202.000000</td>\n      <td>302.000000</td>\n      <td>2.236000e+03</td>\n      <td>5.000000</td>\n      <td>2053.000000</td>\n      <td>236.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.800291e+06</td>\n      <td>81.000000</td>\n      <td>87.000000</td>\n      <td>1220.000000</td>\n      <td>125534.000000</td>\n      <td>2018.000000</td>\n      <td>81.000000</td>\n      <td>87.000000</td>\n      <td>1616.000000</td>\n      <td>1.588863e+07</td>\n      <td>80.000000</td>\n      <td>6619.000000</td>\n      <td>6619.000000</td>\n      <td>9903.000000</td>\n      <td>1.100000e+06</td>\n      <td>5.000000</td>\n      <td>9432.000000</td>\n      <td>1147.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains in total 305.434 rows of data, with 45 columns. Having a large dataset is beneficial for our machine learning purposes. Generally having more data gives us flexibility in choosing relevant features. It also grants us a larger training, testing, and validation datasets when building our models. This can result in higher accuracy, granted the data is well-prepared and have good quality."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c2c862d0232b4a"
  },
  {
   "cell_type": "markdown",
   "id": "92437f4166a20a7e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step 2 - Data preparation\n",
    "\n",
    "From the previous step we saw that data is \n",
    "\n",
    "Columns such as \"Bredde\" and \"Fartøylengde\" is intereperet as object, but they should be float\n",
    "\n",
    "The dataset contains several columns which are unnecessary for our purpose. This includes the message report metadata, as well as duplicate columns which represents the same information in codes instead of words.\n",
    "\n",
    "Let's remove these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef7b6ef0f7520a",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'Starttidspunkt','Startposisjon bredde', 'Startposisjon lengde', 'Hovedområde start',\n",
    "    'Havdybde start', 'Stopptidspunkt', 'Varighet', 'Fangstår', 'Stopposisjon bredde', \n",
    "    'Stopposisjon lengde', 'Hovedområde stopp', 'Havdybde stopp', 'Trekkavstand', 'Redskap FDIR',\n",
    "    'Art - FDIR', 'Art - gruppe', 'Rundvekt', 'Bruttotonnasje annen', \n",
    "    'Bruttotonnasje 1969', 'Bredde', 'Fartøylengde'\n",
    "    ]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafef0794c0f45a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we noticed above, several of the datatypes which are supposed to be continuous numeric values but are interpreted as objects. This is likely because the numbers are all using comma as decimal seperator, which is the standard representation in Norway. There are also several date and time object columns which needs to be converted to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ce708af0a8771",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['Starttidspunkt'] = pd.to_datetime(df['Starttidspunkt'], format='mixed')\n",
    "df['Stopptidspunkt'] = pd.to_datetime(df['Stopptidspunkt'], format='mixed')\n",
    "\n",
    "df['Fartøylengde'] = pd.to_numeric(df['Fartøylengde'].str.replace(',', '.'))\n",
    "df['Bredde'] = pd.to_numeric(df['Bredde'].str.replace(',', '.'))\n",
    "\n",
    "df['Startposisjon bredde'] = pd.to_numeric(df['Startposisjon bredde'].str.replace(',', '.'))\n",
    "df['Startposisjon lengde'] = pd.to_numeric(df['Startposisjon lengde'].str.replace(',', '.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80f6f46e46e8b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Null Values \n",
    "Next, we'll explore null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16734dea6c7996",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61043694d1a01230",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notable observations from this is the \"Bruttotonnasje\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f1484dfea5e5dd",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Filtrer DataFrame for å få rader hvor begge kolonnene ikke er null\n",
    "filtrert_df = df.query(\"`Bruttotonnasje annen`.notnull() and `Bruttotonnasje 1969`.notnull()\")\n",
    "filtrert_df = filtrert_df[['Bruttotonnasje annen', 'Bruttotonnasje 1969']]\n",
    "filtrert_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa1d15adc59fa4",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(filtrert_df['Bruttotonnasje annen'], filtrert_df['Bruttotonnasje 1969'], color='blue', alpha=0.01)\n",
    "plt.title('Bruttotonnasje annen vs 1969')\n",
    "plt.xlabel('Bruttotonnasje annen')\n",
    "plt.ylabel('Bruttotonnasje 1969')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab706ada6d8b9007",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Bruttotonnasje 1969', 'Bruttotonnasje annen'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4200ee2239151",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c6150d61e724db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 3 - Feature Understanding\n",
    "\n",
    "Here we will primarily use univariate analysis to understand the individual variables better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9743a1a63ece1c8b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To start off it's useful to draw histograms of all numeric variables. This will help us understand the variance of the data, help us identify outliers which can negatively affect our models, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31751ab5921153cf",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.hist(bins=60, figsize=(20,15));plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8b91f1be46997",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the resulting histogram its clear that some columns, such as \"Varighet\" and \"Rundvekt\" have outliers that can affect the quality of our models. To further analyse these variables a boxplot is useful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3493e381725fc6e",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def draw_boxplots(variables):\n",
    "    num_of_features = len(variables)\n",
    "    \n",
    "    num_of_columns = 5\n",
    "    num_of_rows = int(np.ceil(num_of_features / num_of_columns))\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=num_of_rows, ncols=num_of_columns, figsize=(15, num_of_rows * num_of_columns))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(variables):\n",
    "        df.boxplot(column=col, ax=axes[i])\n",
    "    \n",
    "    # Hide empty subplots when (number_of_features < num_of_rows * num_of_columns)\n",
    "    for i in range(num_of_features, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c7066cd3f0e5b5",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "heavy_outliers = ['Rundvekt', 'Varighet', 'Trekkavstand', 'Havdybde start']\n",
    "draw_boxplots(heavy_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ed3f67be5e329",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8bd7212039a015",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lets count the numer of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8422346d1ef00",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def find_outlier_value(feature : str):\n",
    "    \"\"\"\n",
    "    Outlier is defined as 1.5 * IQR +- nearest quartile\n",
    "    \n",
    "    :param feature: name of the column in the DataFrame  \n",
    "    :return: tuple (lower_bound, upper_bound) which represents the upper and lower bound of outliers in the DataFrame column. \n",
    "    \"\"\"\n",
    "    q1 = df[feature].quantile(0.25)\n",
    "    q2 = df[feature].quantile(0.75)\n",
    "    iqr = q2 - q1\n",
    "    \n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q2 + 1.5 * iqr\n",
    "    lower_bound_extreme = q1 - 3 * iqr\n",
    "    upper_bound_extreme = q2 + 3 * iqr\n",
    "    \n",
    "    return lower_bound, upper_bound, lower_bound_extreme, upper_bound_extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bfb0acbbd1d42",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "shape = []\n",
    "\n",
    "for feature in heavy_outliers:\n",
    "    lower, upper, lower_extreme, upper_extreme = find_outlier_value(feature)\n",
    "    count = df.query(f'(`{feature}` < @lower) or (`{feature}` > @upper)').shape[0]\n",
    "    count_extreme = df.query(f'(`{feature}` < @lower_extreme) or (`{feature}` > @upper_extreme)').shape[0]\n",
    "    shape.append({'Feature': feature, 'Outliers': count, 'Extreme outliers': count_extreme})\n",
    "\n",
    "outliers_df = pd.DataFrame(shape)\n",
    "print(outliers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efa6e7b10031bf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We have many (extreme) outliers, specificly in the feature \"Rundvekt\". We need to deal with this.\n",
    "\n",
    "Lets explore some normalization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbaa378c33fbc7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "_,_,_,extreme_upper = find_outlier_value('Rundvekt')\n",
    "\n",
    "df['Rundvekt_clipped'] = df['Rundvekt'].clip(0, extreme_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0f0cfe88d403",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['Rundvekt_clipped'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2506d7071938e7c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df['Rundvekt_log'] = np.log(df['Rundvekt'] + 1)\n",
    "df['Varighet_log'] = np.log(df['Varighet'] + 1)\n",
    "df['Trekkavstand_log'] = np.log(df['Trekkavstand'] + 1)\n",
    "\n",
    "df['Rundvekt_log'].hist(bins=50)\n",
    "df['Varighet_log'].hist(bins=50)\n",
    "df['Trekkavstand_log'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287068a1",
   "metadata": {},
   "source": [
    "We can create a dataframe where we exclude all rows where 'rundvekt'-values >= the extreme upper limit outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea3f1a71393a5f",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_capped = df.query('Rundvekt < @extreme_upper')\n",
    "df_capped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65348d23c886c71",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 4 : Feature relationship\n",
    "\n",
    "Now that we have explored the individual variables by themselves. We will now do a multivariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70adfe6dbaa8b2ec",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "sampled_df = df_capped.sample(n=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d018266b0b98fcd9",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='Fartøylengde',\n",
    "                     y='Rundvekt',\n",
    "                     hue='Redskap FDIR',\n",
    "                     data=sampled_df,\n",
    "                     alpha=0.5)\n",
    "ax.set_title('Fartøylengde vs Rundvekt')\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))  # Plasserer legenden på siden\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece4b5a17236ec4",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "features_log = ['Fartøylengde', 'Rundvekt_log', 'Varighet_log','Trekkavstand_log', 'Havdybde start']\n",
    "features = ['Fartøylengde', 'Rundvekt', 'Varighet','Trekkavstand', 'Havdybde start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fead738db5f6f5",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(sampled_df, vars=features, hue='Redskap FDIR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29657aa3b99d281",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(sampled_df, vars=features_log, hue='Redskap FDIR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf43fb",
   "metadata": {},
   "source": [
    "We can create a correlation matrix to explore the linear association between our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7538edeb4d16470",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_corr = df_capped[features].corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbffcc0",
   "metadata": {},
   "source": [
    "To improve readability, we turn it into a heatmap using the Seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebc83e483e5cfd",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0f7c65a6bf33e",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_log = df[['Art - FDIR','Rundvekt_log', 'Redskap FDIR', 'Fartøylengde', 'Havdybde start']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb985dbeca94a7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_log = pd.get_dummies(df_log, columns=['Art - FDIR'])\n",
    "df_log = pd.get_dummies(df_log, columns=['Redskap FDIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfab6ef63fcff5",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_n = df_capped[['Art - FDIR','Rundvekt', 'Redskap FDIR', 'Fartøylengde', 'Havdybde start']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba99abcdd9f7c0c",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_n = pd.get_dummies(df_n, columns=['Art - FDIR'])\n",
    "df_n = pd.get_dummies(df_n, columns=['Redskap FDIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959eb0f94464af7",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def run_model(dataframe, target):\n",
    "    y = dataframe[[target]]\n",
    "    X = dataframe.drop([target], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_estimators': [90, 128],\n",
    "        'max_depth': [12, 15],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    return grid_search.fit(X_train, y_train), X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aede0bb8299a40",
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for (d, t) in [(df_n, 'Rundvekt'), (df_log, 'Rundvekt_log')]:\n",
    "    \n",
    "    model_result, X_test, y_test = run_model(d, t)\n",
    "    \n",
    "    print(t)\n",
    "    \n",
    "    best_params = model_result.best_params_\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    \n",
    "    best_rf = model_result.best_estimator_\n",
    "    \n",
    "    predictions = best_rf.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print(\"MSE:\", mse)\n",
    "    \n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"R^2-score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f63d2",
   "metadata": {},
   "source": [
    "# KNN - regression\n",
    "\n",
    "The code below was written in another notebook and includes more features. This is not something we aim to do in the final edition of the group exam, but it serves as an example of how we currently are exploring machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ff284",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_Knn = df_capped[['Starttidspunkt', 'Art - FDIR','Rundvekt', 'Redskap FDIR', 'Fartøylengde', 'Havdybde start', 'Hovedområde start']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22094e7",
   "metadata": {},
   "source": [
    "Instead of months numbered 1-12, we included the fours seasons instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21b312",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_Knn['month'] = df_Knn['Starttidspunkt'].dt.month\n",
    "df_Knn = df_Knn.drop(['Starttidspunkt'], axis=1)\n",
    "def map_to_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df_Knn['season'] = df_Knn['month'].apply(map_to_season)\n",
    "\n",
    "df_Knn = pd.get_dummies(df_Knn, columns=['season'])\n",
    "df_Knn = df_Knn.drop(['month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44574128",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_Knn = pd.get_dummies(df_Knn, columns=['Art - FDIR'])\n",
    "df_Knn = pd.get_dummies(df_Knn, columns=['Redskap FDIR'])\n",
    "df_Knn = pd.get_dummies(df_Knn, columns=['Hovedområde start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6728fc",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "X = df_Knn.drop(['Rundvekt'], axis=1)\n",
    "y = df_Knn[['Rundvekt']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5ae6e",
   "metadata": {},
   "source": [
    "We can view scaling as a part of the model itself. A pipeline comes in handy for grouping the scaler and the regressor together. \n",
    "We can give the pipeline as an argument to our GridSearchCV along with the different parameters we want to optimize, our chosen scoring metrics, and the number of cross validation groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9348dc",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                     ('knn', KNeighborsRegressor())])\n",
    "\n",
    "params = [{'knn__n_neighbors': [10, 20, 35, 50, 80],\n",
    "         'knn__weights': ['uniform', 'distance']}]\n",
    "\n",
    "gs_knn = GridSearchCV(knn_pipe,\n",
    "                      param_grid=params,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      cv=5)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa6438",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "predictions = gs_knn.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"MSE: {:.2f}\".format(mse))\n",
    "print(\"r2 score: {:.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4181a",
   "metadata": {},
   "source": [
    "Comparing the quality of our two different models does not entirely make sense, since Knn makes use of more features than Random Forest. We do however see that the outcome is very similar for both models that uses the capped live weight as a target variable. The R2 value indicates that none of our models perfectly explain all the variance in the dependent variable. This number did improve when using the log normalized target variable.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
